{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EmoLlama pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read de data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/juliamf/Desktop/CMS-CLS/winter_semester24:25/LLMs/project/public_data_dev/track_a/train/eng.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"Dataset Loaded Successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"The specified file path is not found. Please check the path and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['anger', 'fear', 'joy', 'sadness', 'surprise']\n",
    "label_counts = df[labels].sum()\n",
    "print(label_counts)\n",
    "total = label_counts.sum()\n",
    "print(\"total labels:\", total)\n",
    "print(total/label_counts)\n",
    "\n",
    "# Count how many labels each text has\n",
    "label_combinations = df[labels].sum(axis=1)\n",
    "print(label_combinations.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Tokenize the text\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        # Convert labels to tensor\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": label,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text and labels\n",
    "texts = df[\"text\"].tolist()\n",
    "labels = df[[\"anger\", \"fear\", \"joy\", \"sadness\", \"surprise\"]].values.tolist()  \n",
    "\n",
    "print(\"This shows the texts inputs:\", texts)\n",
    "print(\"This shows the labels for each text input:\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained('lzw1008/Emollama-7b')\n",
    "model = LlamaForCausalLM.from_pretrained('lzw1008/Emollama-7b', device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EmotionDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = EmotionDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "print(train_dataset)\n",
    "print(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Compute pos_weight for BCEWithLogitsLoss\n",
    "labels_tensor = torch.tensor(labels, dtype=torch.float)\n",
    "num_positives = labels_tensor.sum(dim=0)\n",
    "num_negatives = labels_tensor.shape[0] - num_positives\n",
    "pos_weight = num_negatives / num_positives\n",
    "pos_weight_tensor = torch.tensor(pos_weight, dtype=torch.float).to(device)\n",
    "\n",
    "print(label_counts)\n",
    "print(num_positives, num_negatives)\n",
    "print(pos_weight_tensor)\n",
    "\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "def compute_metrics(preds, labels):\n",
    "    preds = (torch.sigmoid(preds) > 0.5).int()  \n",
    "    \n",
    "    f1_per_emotion = f1_score(labels.cpu(), preds.cpu(), average=None)  \n",
    "    macro_f1 = f1_score(labels.cpu(), preds.cpu(), average=\"macro\")\n",
    "    micro_f1 = f1_score(labels.cpu(), preds.cpu(), average=\"micro\")\n",
    "    subset_accuracy = (preds == labels).all(dim=1).float().mean().item()\n",
    "    \n",
    "    return {\"f1_per_emotion\": f1_per_emotion, \"macro_f1\": macro_f1, \"micro_f1\": micro_f1, \"subset_accuracy\": subset_accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        loss = loss_fn(outputs.logits, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}, Training Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    model.eval()\n",
    "    preds, true_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            preds.extend(outputs.logits.cpu())\n",
    "            true_labels.extend(labels.cpu())\n",
    "    \n",
    "    preds = torch.stack(preds)\n",
    "    true_labels = torch.stack(true_labels)\n",
    "    \n",
    "    metrics = compute_metrics(preds, true_labels)\n",
    "    print(f\"Epoch {epoch + 1}, Validation Macro F1: {metrics['macro_f1']:.4f}\")\n",
    "    print(f\"Epoch {epoch + 1}, Validation Micro F1: {metrics['micro_f1']:.4f}\")\n",
    "    print(f\"Epoch {epoch + 1}, Validation Subset Accuracy: {metrics['subset_accuracy']:.4f}\")\n",
    "    print(\"Validation F1 per emotion:\", metrics[\"f1_per_emotion\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotion_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data_path = 'eval_log.csv'\n",
    "filtered_data_path = 'filtered_eval_log.csv'\n",
    "\n",
    "with open(original_data_path, 'r') as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "header = data[0]\n",
    "\n",
    "data = [header] + [line for line in data if line != header]\n",
    "\n",
    "with open(filtered_data_path, 'w') as f:\n",
    "    f.writelines(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(filtered_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>with_attention</th>\n",
       "      <th>with_pos_weights</th>\n",
       "      <th>pretrained_model</th>\n",
       "      <th>which_data</th>\n",
       "      <th>finetune_bert</th>\n",
       "      <th>Anger</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Joy</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>bert</td>\n",
       "      <td>original_eng</td>\n",
       "      <td>False</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.712644</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.712878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>roberta</td>\n",
       "      <td>original_eng</td>\n",
       "      <td>False</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.759494</td>\n",
       "      <td>0.708861</td>\n",
       "      <td>0.698462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>roberta</td>\n",
       "      <td>original_eng</td>\n",
       "      <td>True</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.687418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>bert</td>\n",
       "      <td>original_eng</td>\n",
       "      <td>False</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.687186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>roberta</td>\n",
       "      <td>original_eng</td>\n",
       "      <td>False</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.674177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>bert</td>\n",
       "      <td>original_eng</td>\n",
       "      <td>True</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.732824</td>\n",
       "      <td>0.684932</td>\n",
       "      <td>0.720930</td>\n",
       "      <td>0.520548</td>\n",
       "      <td>0.643475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>distilbert</td>\n",
       "      <td>original_eng</td>\n",
       "      <td>False</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.739726</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.643243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>distilbert</td>\n",
       "      <td>original_eng</td>\n",
       "      <td>True</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.725926</td>\n",
       "      <td>0.452830</td>\n",
       "      <td>0.701299</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>0.640806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>distilbert</td>\n",
       "      <td>original_eng</td>\n",
       "      <td>False</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.701299</td>\n",
       "      <td>0.591549</td>\n",
       "      <td>0.638299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>bert</td>\n",
       "      <td>original_eng</td>\n",
       "      <td>True</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.631620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>distilbert</td>\n",
       "      <td>original_eng</td>\n",
       "      <td>True</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.600061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>bert</td>\n",
       "      <td>original_eng</td>\n",
       "      <td>True</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.582278</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.630137</td>\n",
       "      <td>0.585554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>roberta</td>\n",
       "      <td>original_eng</td>\n",
       "      <td>True</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.404981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    with_attention  with_pos_weights pretrained_model    which_data  \\\n",
       "1             True              True             bert  original_eng   \n",
       "5             True              True          roberta  original_eng   \n",
       "4             True              True          roberta  original_eng   \n",
       "7             True             False             bert  original_eng   \n",
       "11            True             False          roberta  original_eng   \n",
       "12           False              True             bert  original_eng   \n",
       "9             True             False       distilbert  original_eng   \n",
       "2             True              True       distilbert  original_eng   \n",
       "3             True              True       distilbert  original_eng   \n",
       "6             True             False             bert  original_eng   \n",
       "8             True             False       distilbert  original_eng   \n",
       "0             True              True             bert  original_eng   \n",
       "10            True             False          roberta  original_eng   \n",
       "\n",
       "    finetune_bert     Anger      Fear       Joy   Sadness  Surprise  f1_macro  \n",
       "1           False  0.800000  0.714286  0.705882  0.712644  0.631579  0.712878  \n",
       "5           False  0.571429  0.755556  0.696970  0.759494  0.708861  0.698462  \n",
       "4            True  0.585366  0.716418  0.689655  0.750000  0.695652  0.687418  \n",
       "7           False  0.640000  0.755906  0.615385  0.724638  0.700000  0.687186  \n",
       "11          False  0.625000  0.736842  0.653061  0.620690  0.735294  0.674177  \n",
       "12           True  0.558140  0.732824  0.684932  0.720930  0.520548  0.643475  \n",
       "9           False  0.615385  0.742424  0.627451  0.739726  0.491228  0.643243  \n",
       "2            True  0.648649  0.725926  0.452830  0.701299  0.675325  0.640806  \n",
       "3           False  0.583333  0.666667  0.648649  0.701299  0.591549  0.638299  \n",
       "6            True  0.645161  0.765957  0.520000  0.645161  0.581818  0.631620  \n",
       "8            True  0.521739  0.741259  0.560000  0.666667  0.510638  0.600061  \n",
       "0            True  0.425532  0.596491  0.582278  0.693333  0.630137  0.585554  \n",
       "10           True  0.466667  0.736111  0.380952  0.441176  0.000000  0.404981  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sort_values(by='f1_macro', inplace=True, ascending=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.round(4).to_latex('eval_log.tex', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

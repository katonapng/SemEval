{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from deep_translator import GoogleTranslator\n",
    "from fastai.callback.progress import CSVLogger\n",
    "from fastai.callback.tracker import EarlyStoppingCallback, SaveModelCallback\n",
    "from fastai.learner import DataLoaders\n",
    "from fastai.metrics import RocAuc\n",
    "from fastai.optimizer import OptimWrapper\n",
    "from fastai.vision.all import Learner\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import DistilBertTokenizerFast, DistilBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "SIM_THRESHOLD = 0.80\n",
    "# 5/0\n",
    "data_translated = {}\n",
    "with open('data_translated.pkl', 'rb') as f:\n",
    "    data_translated = pickle.load(f)\n",
    "\n",
    "labels = ['Anger', 'Fear', 'Joy', 'Sadness', 'Surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_eng = pd.read_csv('public_data/train/track_a/eng.csv')\n",
    "original_eng['comment'] = 'original_eng'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_translated = original_eng\n",
    "# df_translated = pd.concat([original_eng] + list(data_translated.values()), ignore_index=True)\n",
    "# df_translated.to_csv('df_translated.csv', index=False)\n",
    "# display(df_translated.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = original_eng.text.str.len().max()\n",
    "# MAX_LEN = df_translated.text.str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_translated = df_translated.dropna(subset=['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset definition\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len=256):\n",
    "        self.texts = data[\"text\"].tolist()\n",
    "        self.labels = data[[\"Anger\", \"Fear\", \"Joy\", \"Sadness\", \"Surprise\"]].values\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        labels = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        encodings = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        input_ids = encodings[\"input_ids\"].squeeze(0)\n",
    "        attention_mask = encodings[\"attention_mask\"].squeeze(0)\n",
    "        return (input_ids, attention_mask), labels\n",
    "\n",
    "class CorrelationAwareLoss(nn.Module):\n",
    "    def __init__(self, pos_weight, correlation_matrix, base_loss=nn.BCEWithLogitsLoss):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pos_weight (torch.Tensor): Weights for positive samples of each class.\n",
    "            correlation_matrix (torch.Tensor): Correlation matrix of labels.\n",
    "            base_loss (nn.Module): Base loss function (default: BCEWithLogitsLoss).\n",
    "        \"\"\"\n",
    "        super(CorrelationAwareLoss, self).__init__()\n",
    "        self.pos_weight = pos_weight\n",
    "        self.correlation_matrix = correlation_matrix\n",
    "        self.base_loss = base_loss(pos_weight=self.pos_weight)\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        # Compute the weighted BCEWithLogitsLoss\n",
    "        weighted_loss = self.base_loss(logits, labels)\n",
    "\n",
    "        # Compute pairwise correlation adjustment\n",
    "        preds = torch.sigmoid(logits)  # Convert logits to probabilities\n",
    "        batch_size = preds.size(0)\n",
    "\n",
    "        # Penalize based on how predictions align with label correlation\n",
    "        correlation_loss = torch.sum(\n",
    "            (preds.unsqueeze(2) - preds.unsqueeze(1)) * self.correlation_matrix.unsqueeze(0)\n",
    "        ) / batch_size\n",
    "\n",
    "        # Combine the base loss and correlation loss\n",
    "        return weighted_loss + 0.1 * correlation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(AttentionPooling, self).__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Softmax(dim=1)  # Apply softmax across the sequence length\n",
    "        )\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask):\n",
    "        # Apply attention mask to ignore [PAD] tokens\n",
    "        weights = self.attention(hidden_states)\n",
    "        weights = weights * attention_mask.unsqueeze(-1)  # Apply mask\n",
    "\n",
    "        # Normalize attention weights to sum to 1\n",
    "        weights = weights / (weights.sum(dim=1, keepdim=True) + 1e-9)\n",
    "\n",
    "        # Weighted sum of hidden states\n",
    "        pooled_output = torch.sum(weights * hidden_states, dim=1)\n",
    "        return pooled_output, weights\n",
    "\n",
    "\n",
    "\n",
    "# BERT + Multi-Head Attention Pooling for Multi-label Emotion Classification\n",
    "class DistilBertMultiLabel(torch.nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(DistilBertMultiLabel, self).__init__()\n",
    "        self.bert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\", num_labels=num_labels)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "        hidden_size = self.bert.config.hidden_size  # Typically 768\n",
    "\n",
    "        # Attention Pooling Layer\n",
    "        self.attention_pooling = AttentionPooling(hidden_size)\n",
    "\n",
    "        # Classification Head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, num_labels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_ids, attention_mask = x\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_states = outputs.last_hidden_state  # Shape: (batch_size, seq_len, hidden_size)\n",
    "\n",
    "        # Apply Attention Pooling\n",
    "        pooled_output, attention_weights = self.attention_pooling(hidden_states, attention_mask)\n",
    "\n",
    "        # Classification\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop nas from the dataset where the text is missing\n",
    "df_translated = df_translated.dropna(subset=['text'])\n",
    "# df_translated = df_translated[df_translated['comment'].isin(('backtranslate_de', 'original_eng'))]\n",
    "df_translated = df_translated[df_translated['comment'] != 'backtranslate_de']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = train_test_split(df_translated, test_size=0.25, random_state=42)\n",
    "# train_data, valid_data = train_test_split(original_eng, test_size=0.25, random_state=42)\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data manipulation start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "PART_LEN = 127\n",
    "\n",
    "def augment(df):\n",
    "    df['text'] = df['text'].apply(lambda x: x[:PART_LEN])\n",
    "    df['temp'] = 1\n",
    "    square = df.merge(df, on='temp', suffixes=('_left', '_right'))\n",
    "    square['text'] = square['text_left'] + ' ' + square['text_right']\n",
    "    for e in labels:\n",
    "        square[e] = square[[e + '_left', e + '_right']].max(axis=1)\n",
    "    square = square[['text', *labels, 'id_left', 'id_right']]\n",
    "    return square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_augmented = augment(train_data)\n",
    "valid_data_augmented = augment(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_augmented_downsampled = train_data_augmented.sample(n=30000, random_state=42)\n",
    "# valid_data_augmented_downsampled = valid_data_augmented.sample(n=10000, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_emo_count = 5000\n",
    "train_data_augmented['emo_count'] = train_data_augmented[labels].sum(axis=1)\n",
    "dfs = []\n",
    "for i in range(5):\n",
    "    dfs.append(train_data_augmented.query(f\"emo_count == {i}\").sample(n=target_emo_count, random_state=42))\n",
    "train_data_augmented_downsampled = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_emo_count = 1250\n",
    "valid_data_augmented['emo_count'] = valid_data_augmented[labels].sum(axis=1)\n",
    "dfs = []\n",
    "for i in range(5):\n",
    "    dfs.append(valid_data_augmented.query(f\"emo_count == {i}\").sample(n=target_emo_count, random_state=42))\n",
    "valid_data_augmented_downsampled = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Anger', 'Fear', 'Joy', 'Sadness', 'Surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_627170/1131106885.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_weight_tensor = torch.tensor(pos_weight, dtype=torch.float).to(device)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = EmotionDataset(\n",
    "    train_data_augmented_downsampled,\n",
    "    tokenizer\n",
    ")\n",
    "valid_dataset = EmotionDataset(\n",
    "    valid_data_augmented_downsampled,\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16)\n",
    "\n",
    "# Define model and training components\n",
    "#device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda\")\n",
    "print(f\"Using device: {device}\")\n",
    "model = DistilBertMultiLabel(len(labels)).to(device)\n",
    "\n",
    "\n",
    "# Compute pos_weight for BCEWithLogitsLoss \n",
    "values = train_data_augmented_downsampled[labels].values.tolist()\n",
    "labels_tensor = torch.tensor(values, dtype=torch.float)\n",
    "num_positives = labels_tensor.sum(dim=0)\n",
    "num_negatives = labels_tensor.shape[0] - num_positives\n",
    "pos_weight = num_negatives / num_positives\n",
    "pos_weight_tensor = torch.tensor(pos_weight, dtype=torch.float).to(device)\n",
    "\n",
    "# Define the loss function\n",
    "loss_func = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
    "\n",
    "# loss_func = CorrelationAwareLoss(pos_weight=class_weights, correlation_matrix=correlation_matrix)\n",
    "# loss_func = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add timestamp to the directory name\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "name = \"distilbert_attention_square_augmented\"\n",
    "output_path = Path(f'model_{name}_{timestamp}')\n",
    "output_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# FastAI DataLoaders\n",
    "dls = DataLoaders(train_loader, valid_loader, device=device)\n",
    "\n",
    "# Define Learner\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    loss_func=loss_func,\n",
    "    opt_func=partial(OptimWrapper, opt=torch.optim.AdamW),\n",
    "    metrics=[RocAuc()],\n",
    "    path=output_path\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "cbs = [\n",
    "    SaveModelCallback(monitor='valid_loss', fname='best_valid'),\n",
    "    EarlyStoppingCallback(monitor='valid_loss', patience=9),\n",
    "    CSVLogger()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/5 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1563 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 1.2418713569641113.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_one_cycle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_opt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcbs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/fastai/callback/schedule.py:121\u001b[0m, in \u001b[0;36mfit_one_cycle\u001b[0;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[1;32m    118\u001b[0m lr_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([h[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mhypers])\n\u001b[1;32m    119\u001b[0m scheds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: combined_cos(pct_start, lr_max\u001b[38;5;241m/\u001b[39mdiv, lr_max, lr_max\u001b[38;5;241m/\u001b[39mdiv_final),\n\u001b[1;32m    120\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmom\u001b[39m\u001b[38;5;124m'\u001b[39m: combined_cos(pct_start, \u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoms \u001b[38;5;28;01mif\u001b[39;00m moms \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m moms))}\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mParamScheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscheds\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcbs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_opt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_opt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_epoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/fastai/learner.py:266\u001b[0m, in \u001b[0;36mLearner.fit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mset_hypers(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr \u001b[38;5;28;01mif\u001b[39;00m lr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lr)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch \u001b[38;5;241m=\u001b[39m n_epoch\n\u001b[0;32m--> 266\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelFitException\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_end_cleanup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/fastai/learner.py:201\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/fastai/learner.py:255\u001b[0m, in \u001b[0;36mLearner._do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch):\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch\u001b[38;5;241m=\u001b[39mepoch\n\u001b[0;32m--> 255\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelEpochException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/fastai/learner.py:201\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/fastai/learner.py:250\u001b[0m, in \u001b[0;36mLearner._do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_do_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_epoch_train()\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/fastai/learner.py:246\u001b[0m, in \u001b[0;36mLearner._do_epoch_validate\u001b[0;34m(self, ds_idx, dl)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: dl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls[ds_idx]\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl \u001b[38;5;241m=\u001b[39m dl\n\u001b[0;32m--> 246\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalidate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelValidException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/fastai/learner.py:201\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/fastai/learner.py:207\u001b[0m, in \u001b[0;36mLearner.all_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mall_batches\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl)\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/fastai/learner.py:237\u001b[0m, in \u001b[0;36mLearner.one_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    235\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_device(b)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split(b)\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_one_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelBatchException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/fastai/learner.py:203\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  f()\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 203\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mafter_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mevent_type\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m;  final()\n",
      "File \u001b[0;32m/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/fastai/learner.py:174\u001b[0m, in \u001b[0;36mLearner.__call__\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, event_name): \u001b[43mL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/fastcore/foundation.py:163\u001b[0m, in \u001b[0;36mL.map\u001b[0;34m(self, f, *args, **kwargs)\u001b[0m\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[43mmap_ex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/fastcore/basics.py:934\u001b[0m, in \u001b[0;36mmap_ex\u001b[0;34m(iterable, f, gen, *args, **kwargs)\u001b[0m\n\u001b[1;32m    932\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(g, iterable)\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gen: \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m--> 934\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/fastcore/basics.py:919\u001b[0m, in \u001b[0;36mbind.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v,_Arg): kwargs[k] \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mpop(v\u001b[38;5;241m.\u001b[39mi)\n\u001b[1;32m    918\u001b[0m fargs \u001b[38;5;241m=\u001b[39m [args[x\u001b[38;5;241m.\u001b[39mi] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, _Arg) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpargs] \u001b[38;5;241m+\u001b[39m args[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 919\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/fastai/learner.py:178\u001b[0m, in \u001b[0;36mLearner._call_one\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_call_one\u001b[39m(\u001b[38;5;28mself\u001b[39m, event_name):\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(event, event_name): \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcbs\u001b[38;5;241m.\u001b[39msorted(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[43mcb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/fastai/callback/core.py:62\u001b[0m, in \u001b[0;36mCallback.__call__\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m     60\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun \u001b[38;5;129;01mand\u001b[39;00m _run: \n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: res \u001b[38;5;241m=\u001b[39m \u001b[43mgetcallable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (CancelBatchException, CancelBackwardException, CancelEpochException, CancelFitException, CancelStepException, CancelTrainException, CancelValidException): \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e: \u001b[38;5;28;01mraise\u001b[39;00m modify_exception(e, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mException occured in `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` when calling event `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/fastai/learner.py:562\u001b[0m, in \u001b[0;36mRecorder.after_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myb) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    561\u001b[0m mets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_mets \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_valid_mets\n\u001b[0;32m--> 562\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m met \u001b[38;5;129;01min\u001b[39;00m mets: \u001b[43mmet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccumulate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining: \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlrs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mhypers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/fastai/learner.py:497\u001b[0m, in \u001b[0;36mAvgLoss.accumulate\u001b[0;34m(self, learn)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21maccumulate\u001b[39m(\u001b[38;5;28mself\u001b[39m, learn):\n\u001b[1;32m    496\u001b[0m     bs \u001b[38;5;241m=\u001b[39m find_bs(learn\u001b[38;5;241m.\u001b[39myb)\n\u001b[0;32m--> 497\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_detach\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m*\u001b[39mbs\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcount \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m bs\n",
      "File \u001b[0;32m/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/fastai/learner.py:356\u001b[0m, in \u001b[0;36mLearner.to_detach\u001b[0;34m(self, b, cpu, gather)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_detach\u001b[39m(\u001b[38;5;28mself\u001b[39m,b,cpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,gather\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl\u001b[38;5;241m.\u001b[39mto_detach(b,cpu,gather) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdl\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28;01mNone\u001b[39;00m),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto_detach\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mto_detach\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgather\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/fastai/torch_core.py:246\u001b[0m, in \u001b[0;36mto_detach\u001b[0;34m(b, cpu, gather)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gather: x \u001b[38;5;241m=\u001b[39m maybe_gather(x)\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcpu() \u001b[38;5;28;01mif\u001b[39;00m cpu \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[0;32m--> 246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_inner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgather\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/fastai/torch_core.py:226\u001b[0m, in \u001b[0;36mapply\u001b[0;34m(func, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_listy(x): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(x)([apply(func, o, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m x])\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x,(\u001b[38;5;28mdict\u001b[39m,MutableMapping)): \u001b[38;5;28;01mreturn\u001b[39;00m {k: apply(func, v, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m--> 226\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m retain_type(res, x)\n",
      "File \u001b[0;32m/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/fastai/torch_core.py:245\u001b[0m, in \u001b[0;36mto_detach.<locals>._inner\u001b[0;34m(x, cpu, gather)\u001b[0m\n\u001b[1;32m    243\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gather: x \u001b[38;5;241m=\u001b[39m maybe_gather(x)\n\u001b[0;32m--> 245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m cpu \u001b[38;5;28;01melse\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(n_epoch=5, reset_opt=True, lr_max=1e-4, wd=1e-2, cbs=cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_loss()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('model_distilbert_attention_square_augmented_2025-02-07_23-05-38/models/model_last.pth')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save learn model in pth format\n",
    "learn.save(f'model_last')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_and_save_with_texts(learner, texts, output_csv):\n",
    "#     if learner.dls.valid is None:\n",
    "#         raise ValueError(\"The Learner does not have a validation DataLoader.\")\n",
    "    \n",
    "#     preds, targs = learner.get_preds(dl=learner.dls.valid)\n",
    "\n",
    "#     preds_binary = (preds > 0).int()\n",
    "\n",
    "#     results_df = pd.DataFrame({\n",
    "#         \"Text\": texts,\n",
    "#         \"True Labels\": [list(map(int, x)) for x in targs],\n",
    "#         \"Predicted Labels\": [list(map(int, x)) for x in preds_binary]\n",
    "#     })\n",
    "\n",
    "#     results_df.to_csv(output_csv, index=False)\n",
    "#     print(f\"Predictions saved to {output_csv}\")\n",
    "\n",
    "\n",
    "# results_path = Path(f\"results_{name}_{timestamp}\")\n",
    "# results_path.mkdir(exist_ok=True, parents=True)\n",
    "# output_csv = f\"{results_path}/validation_predictions.csv\"\n",
    "\n",
    "# # Load best model\n",
    "# best_model_path = output_path / 'models' / 'best_valid.pth'\n",
    "# #learn.load(best_model_path.stem)\n",
    "\n",
    "# # Get validation texts and make predictions\n",
    "# validation_texts = valid_data[\"text\"].tolist()\n",
    "# predict_and_save_with_texts(learn, validation_texts, output_csv=output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_dev_track_a_00001</td>\n",
       "      <td>Older sister (23 at the time) is a Scumbag Stacy. Older sister (23 at the time) is a Scumbag Stacy.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eng_dev_track_a_00002</td>\n",
       "      <td>And I laughed like this: garhahagar, because my mouth was full of cotton and shit to bite down on and sharp objects and drills. And I laughed like this: garhahagar, because my mouth was full of cotton and shit to bite down on and sharp objects and drills.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng_dev_track_a_00003</td>\n",
       "      <td>It overflowed and brown shitty diarrhea water came flooding under the stall wall into my wife's stall. It overflowed and brown shitty diarrhea water came flooding under the stall wall into my wife's stall.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eng_dev_track_a_00004</td>\n",
       "      <td>Its very dark and foggy. Its very dark and foggy.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eng_dev_track_a_00005</td>\n",
       "      <td>Then she tried to, like, have sex with/strangle everyone. Then she tried to, like, have sex with/strangle everyone.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id  \\\n",
       "0  eng_dev_track_a_00001   \n",
       "1  eng_dev_track_a_00002   \n",
       "2  eng_dev_track_a_00003   \n",
       "3  eng_dev_track_a_00004   \n",
       "4  eng_dev_track_a_00005   \n",
       "\n",
       "                                                                                                                                                                                                                                                              text  \\\n",
       "0                                                                                                                                                              Older sister (23 at the time) is a Scumbag Stacy. Older sister (23 at the time) is a Scumbag Stacy.   \n",
       "1  And I laughed like this: garhahagar, because my mouth was full of cotton and shit to bite down on and sharp objects and drills. And I laughed like this: garhahagar, because my mouth was full of cotton and shit to bite down on and sharp objects and drills.   \n",
       "2                                                    It overflowed and brown shitty diarrhea water came flooding under the stall wall into my wife's stall. It overflowed and brown shitty diarrhea water came flooding under the stall wall into my wife's stall.   \n",
       "3                                                                                                                                                                                                                Its very dark and foggy. Its very dark and foggy.   \n",
       "4                                                                                                                                              Then she tried to, like, have sex with/strangle everyone. Then she tried to, like, have sex with/strangle everyone.   \n",
       "\n",
       "   anger  fear  joy  sadness  surprise  \n",
       "0      1     0    0        0         0  \n",
       "1      0     1    0        0         0  \n",
       "2      1     1    0        1         1  \n",
       "3      0     1    0        0         0  \n",
       "4      1     1    0        0         1  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dev_df = pd.read_csv('public_data_test/track_a/dev/eng.csv')\n",
    "# dev_df = valid_data\n",
    "dev_df['text'] = dev_df['text'].apply(lambda x: x[:PART_LEN])\n",
    "dev_df['text'] = dev_df['text'] + ' ' + dev_df['text']\n",
    "dev_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/fastai/learner.py:61: UserWarning: Saved file doesn't contain an optimizer state.\n",
      "  elif with_opt: warn(\"Saved file doesn't contain an optimizer state.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to results_distilbert_attention_square_augmented_2025-02-07_23-05-38/dev_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Function to preprocess and predict\n",
    "def predict_classes(learner, texts, tokenizer, max_len=256):\n",
    "    predictions = []\n",
    "\n",
    "    learner.model.eval()\n",
    "    with torch.no_grad():\n",
    "        for text in texts:\n",
    "            # Tokenize and prepare input\n",
    "            encoded = tokenizer(\n",
    "                text,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=max_len,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            input_ids = encoded[\"input_ids\"].to(device)\n",
    "            attention_mask = encoded[\"attention_mask\"].to(device)\n",
    "\n",
    "            # Make predictions\n",
    "            logits = learner.model((input_ids, attention_mask))\n",
    "            probs = torch.sigmoid(logits)  # Multi-label classification\n",
    "            predicted_labels = (probs > 0.5).int().tolist()[0]  # Binary predictions\n",
    "            # predicted_labels = (logits > 0).int().tolist()[0]  # Binary predictions\n",
    "\n",
    "            predictions.append(predicted_labels)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# Load best model\n",
    "best_model_path = output_path / 'models' / 'best_valid.pth'\n",
    "learn.load(best_model_path.stem)\n",
    "\n",
    "\n",
    "# Apply the model to the dataset\n",
    "# drop dev_df with missing text\n",
    "dev_df = dev_df.dropna(subset=['text'])\n",
    "texts = dev_df[\"text\"].tolist()  # Handle missing texts\n",
    "predictions = predict_classes(learn, texts, tokenizer)\n",
    "\n",
    "# Add predictions to the DataFrame\n",
    "emotion_labels = [\"pred_anger\", \"pred_fear\", \"pred_joy\", \"pred_sadness\", \"pred_surprise\"]\n",
    "prediction_df = pd.DataFrame(predictions, columns=emotion_labels)\n",
    "dev_df[emotion_labels] = prediction_df.values\n",
    "\n",
    "# Save the true and predicted labels as string lists\n",
    "# dev_df[\"True Labels\"] = dev_df[[\"Anger\", \"Fear\", \"Joy\", \"Sadness\", \"Surprise\"]].values.tolist()\n",
    "dev_df[\"True Labels\"] = dev_df[[\"anger\", \"fear\", \"joy\", \"sadness\", \"surprise\"]].values.tolist()\n",
    "\n",
    "dev_df[\"Predicted Labels\"] = dev_df[emotion_labels].values.tolist()\n",
    "\n",
    "# Convert lists to strings\n",
    "dev_df[\"True Labels\"] = dev_df[\"True Labels\"].apply(lambda x: str(x))\n",
    "dev_df[\"Predicted Labels\"] = dev_df[\"Predicted Labels\"].apply(lambda x: str(x))\n",
    "\n",
    "# Save the updated DataFrame to a new file\n",
    "results_path = Path(f\"results_{name}_{timestamp}\")\n",
    "results_path.mkdir(exist_ok=True, parents=True)\n",
    "output_csv = f\"{results_path}/dev_predictions.csv\"\n",
    "\n",
    "dev_df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Predictions saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertEmotionClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertEmotionClassifier(5)\n",
    "model_path =  os.path.join(base_dir, output_path, \"models\", \"best_valid.pth\")\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data_path =  os.path.join(base_dir, \"public_data\", \"dev\", \"track_a\", \"eng_a.csv\")\n",
    "data_eng = pd.read_csv(dev_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BertEmotionClassifier.forward() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Apply the model to the dataset\u001b[39;00m\n\u001b[1;32m     42\u001b[0m texts \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()  \u001b[38;5;66;03m# Handle missing texts\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Add predictions to the DataFrame\u001b[39;00m\n\u001b[1;32m     46\u001b[0m emotion_labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnger\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJoy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSadness\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSurprise\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[0;32mIn[17], line 33\u001b[0m, in \u001b[0;36mpredict_classes\u001b[0;34m(model, texts, tokenizer, max_len)\u001b[0m\n\u001b[1;32m     30\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m encoded[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(logits)  \u001b[38;5;66;03m# Multi-label classification\u001b[39;00m\n\u001b[1;32m     35\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m (probs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mint()\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Binary predictions\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/trdr/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/trdr/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: BertEmotionClassifier.forward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Function to preprocess and predict\n",
    "def predict_classes(model, texts, tokenizer, max_len=128):\n",
    "    \"\"\"\n",
    "    Predict classes for a list of texts using the provided model and tokenizer.\n",
    "\n",
    "    Args:\n",
    "        model: The loaded PyTorch model.\n",
    "        texts: A list of input sentences.\n",
    "        tokenizer: The tokenizer for preprocessing the input.\n",
    "        max_len: Maximum sequence length for tokenization.\n",
    "\n",
    "    Returns:\n",
    "        predictions: Predicted labels for the input texts.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for text in texts:\n",
    "            # Tokenize and prepare input\n",
    "            encoded = tokenizer(\n",
    "                text,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=max_len,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            input_ids = encoded[\"input_ids\"]\n",
    "            attention_mask = encoded[\"attention_mask\"]\n",
    "\n",
    "            # Make predictions\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            print(logits)\n",
    "            probs = torch.sigmoid(logits)  # Multi-label classification\n",
    "            predicted_labels = (probs > 0.5).int().tolist()[0]  # Binary predictions\n",
    "\n",
    "            predictions.append(predicted_labels)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Apply the model to the dataset\n",
    "texts = data_eng[\"text\"].fillna(\"\").tolist()  # Handle missing texts\n",
    "predictions = predict_classes(model, texts, tokenizer)\n",
    "\n",
    "# Add predictions to the DataFrame\n",
    "emotion_labels = [\"Anger\", \"Fear\", \"Joy\", \"Sadness\", \"Surprise\"]\n",
    "prediction_df = pd.DataFrame(predictions, columns=emotion_labels)\n",
    "data_eng[emotion_labels] = prediction_df\n",
    "\n",
    "# Save the updated DataFrame to a new file\n",
    "output_path =  os.path.join(base_dir, \"public_data\", \"dev\", \"track_a\", \"eng_with_predictions_CAL.csv\")\n",
    "data_eng.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Predictions saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to /Users/vav/Documents/TUD/Semester 3/LLM/Project/public_data_dev/track_a/dev/eng_with_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Correct the device for inference\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Load the trained model and set it to evaluation mode\n",
    "model = BertEmotionClassifier(5)\n",
    "model.load_state_dict(torch.load(\"/Users/vav/Documents/TUD/Semester 3/LLM/Project/MIL_BCE_weights/models/best_valid.pth\", map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Define the function for preprocessing and predicting\n",
    "def predict_classes(model, texts, tokenizer, max_len=128):\n",
    "    \"\"\"\n",
    "    Predict classes for a list of texts using the provided model and tokenizer.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for text in texts:\n",
    "            # Tokenize and prepare input\n",
    "            encoded = tokenizer(\n",
    "                text,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=max_len,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            input_ids = encoded[\"input_ids\"].to(device)\n",
    "            attention_mask = encoded[\"attention_mask\"].to(device)\n",
    "\n",
    "            # Make predictions\n",
    "            logits = model((input_ids, attention_mask))\n",
    "            probs = torch.sigmoid(logits)  # Multi-label classification\n",
    "            predicted_labels = (probs > 0.5).int().tolist()[0]\n",
    "\n",
    "            predictions.append(predicted_labels)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Load and preprocess the new dataset\n",
    "dev_data_path = \"/Users/vav/Documents/TUD/Semester 3/LLM/Project/public_data_dev/track_a/dev/eng.csv\"\n",
    "data_eng = pd.read_csv(dev_data_path)\n",
    "texts = data_eng[\"text\"].fillna(\"\").tolist()  # Handle missing texts\n",
    "\n",
    "# Make predictions\n",
    "predictions = predict_classes(model, texts, tokenizer)\n",
    "\n",
    "# Add predictions to the DataFrame\n",
    "emotion_labels = [\"anger\", \"fear\", \"joy\", \"sadness\", \"surprise\"]\n",
    "prediction_df = pd.DataFrame(predictions, columns=emotion_labels)\n",
    "data_eng[emotion_labels] = prediction_df\n",
    "\n",
    "# Save the updated DataFrame to a new file\n",
    "output_path = \"/Users/vav/Documents/TUD/Semester 3/LLM/Project/public_data_dev/track_a/dev/eng_with_predictions.csv\"\n",
    "data_eng.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Predictions saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

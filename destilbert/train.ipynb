{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import DistilBertTokenizerFast, DistilBertModel, Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Load Data\n",
    "data_path = \"../public_data/train/track_a/eng.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Step 2: Prepare Labels (multi-label)\n",
    "emotions = [\"Anger\", \"Fear\", \"Joy\", \"Sadness\", \"Surprise\"]\n",
    "\n",
    "# Step 3: Train-Validation-Test Split\n",
    "train_data, val_data = train_test_split(data, test_size=0.25, random_state=42)\n",
    "# val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"../public_data_test/track_a/dev/eng.csv\")\n",
    "# uppercase solumns 'anger', 'fear', 'joy', 'sadness', 'surprise' in test_data\n",
    "test_data.rename(columns={'anger': 'Anger', 'fear': 'Fear', 'joy': 'Joy', 'sadness': 'Sadness', 'surprise': 'Surprise'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Custom Dataset Class\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len=128):\n",
    "        self.texts = data[\"text\"].tolist()\n",
    "        self.labels = data[[\"Anger\", \"Fear\", \"Joy\", \"Sadness\", \"Surprise\"]].values\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        labels = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        encodings = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        input_ids = encodings[\"input_ids\"].squeeze(0)\n",
    "        attention_mask = encodings[\"attention_mask\"].squeeze(0)\n",
    "        return (input_ids, attention_mask), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Tokenization\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "train_dataset = EmotionDataset(train_data, tokenizer)\n",
    "val_dataset = EmotionDataset(val_data, tokenizer)\n",
    "test_dataset = EmotionDataset(test_data, tokenizer)\n",
    "# test_dataset = Dataset.from_pandas(test_data)\n",
    "\n",
    "# Step 5: Model Definition\n",
    "class DistilBertMultiLabel(torch.nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(DistilBertMultiLabel, self).__init__()\n",
    "        self.bert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\", num_labels=num_labels)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_ids, attention_mask = x\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = self.dropout(outputs.pooler_output)\n",
    "        return self.fc(pooled_output)\n",
    "    \n",
    "\n",
    "# # Model definition\n",
    "# class BertEmotionClassifier(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super(BertEmotionClassifier, self).__init__()\n",
    "#         self.bert = DistilBertModel.from_pretrained('bert-base-uncased')\n",
    "#         self.dropout = nn.Dropout(0.3)\n",
    "#         self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         input_ids, attention_mask = x\n",
    "#         outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         pooled_output = self.dropout(outputs.pooler_output)\n",
    "#         return self.fc(pooled_output)\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "num_labels = len(emotions)\n",
    "model = DistilBertMultiLabel(num_labels=num_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>Anger</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Joy</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>eng_train_track_a_01585</td>\n",
       "      <td>I gasped and my heart began to flutter, it was...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>eng_train_track_a_01801</td>\n",
       "      <td>She is awesome and totally not Bride-zilla-y a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2429</th>\n",
       "      <td>eng_train_track_a_02430</td>\n",
       "      <td>I go to New York City about once a year to vis...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>eng_train_track_a_01707</td>\n",
       "      <td>I can see it in my head.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>eng_train_track_a_01028</td>\n",
       "      <td>Awkward lunch time... sometimes I think my mou...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>eng_train_track_a_01639</td>\n",
       "      <td>At one point, I got pissed at Bryce for holdin...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>eng_train_track_a_01096</td>\n",
       "      <td>3rd I really don't know... Any of the main cha...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>eng_train_track_a_01131</td>\n",
       "      <td>I blinked a few times and fought with myself t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>eng_train_track_a_01295</td>\n",
       "      <td>Grandma died of an massive heart attack before...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>eng_train_track_a_00861</td>\n",
       "      <td>My eyes followed, noting that there was just t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2076 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           id  \\\n",
       "1584  eng_train_track_a_01585   \n",
       "1800  eng_train_track_a_01801   \n",
       "2429  eng_train_track_a_02430   \n",
       "1706  eng_train_track_a_01707   \n",
       "1027  eng_train_track_a_01028   \n",
       "...                       ...   \n",
       "1638  eng_train_track_a_01639   \n",
       "1095  eng_train_track_a_01096   \n",
       "1130  eng_train_track_a_01131   \n",
       "1294  eng_train_track_a_01295   \n",
       "860   eng_train_track_a_00861   \n",
       "\n",
       "                                                   text  Anger  Fear  Joy  \\\n",
       "1584  I gasped and my heart began to flutter, it was...      0     1    0   \n",
       "1800  She is awesome and totally not Bride-zilla-y a...      0     0    1   \n",
       "2429  I go to New York City about once a year to vis...      0     0    1   \n",
       "1706                           I can see it in my head.      0     0    0   \n",
       "1027  Awkward lunch time... sometimes I think my mou...      0     1    0   \n",
       "...                                                 ...    ...   ...  ...   \n",
       "1638  At one point, I got pissed at Bryce for holdin...      1     0    0   \n",
       "1095  3rd I really don't know... Any of the main cha...      0     1    0   \n",
       "1130  I blinked a few times and fought with myself t...      0     1    0   \n",
       "1294  Grandma died of an massive heart attack before...      0     1    0   \n",
       "860   My eyes followed, noting that there was just t...      0     0    0   \n",
       "\n",
       "      Sadness  Surprise  \n",
       "1584        0         1  \n",
       "1800        0         1  \n",
       "2429        0         0  \n",
       "1706        0         0  \n",
       "1027        1         0  \n",
       "...       ...       ...  \n",
       "1638        0         0  \n",
       "1095        0         0  \n",
       "1130        1         1  \n",
       "1294        1         0  \n",
       "860         0         0  \n",
       "\n",
       "[2076 rows x 7 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 6: Metrics for Multi-label Classification\n",
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "    preds = torch.sigmoid(torch.tensor(logits)) > 0.5  # Thresholding at 0.5\n",
    "    f1 = f1_score(labels, preds, average=\"macro\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}\n",
    "\n",
    "# Step 7: Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"distilbert-multilabel-emotion\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=2e-5,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    save_total_limit=2,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FastAI DataLoaders\n",
    "dls = DataLoaders(train_loader, valid_loader, device=device)\n",
    "output_path = Path('base_model_2')\n",
    "output_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Define Learner\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    loss_func=loss_func,\n",
    "    opt_func=partial(OptimWrapper, opt=torch.optim.AdamW),\n",
    "    metrics=[RocAuc()],\n",
    "    path=output_path\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "cbs = [\n",
    "    SaveModelCallback(monitor='valid_loss', fname='best_valid'),\n",
    "    EarlyStoppingCallback(monitor='valid_loss', patience=9),\n",
    "    CSVLogger()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2894144/3093883908.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Step 8: Trainer Setup\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=val_dataset,\n",
    "#     tokenizer=tokenizer,\n",
    "#     compute_metrics=compute_metrics\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EmotionDataset' object has no attribute '_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Step 9: Train the Model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/transformers/trainer.py:2171\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2169\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2172\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/transformers/trainer.py:2200\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2198\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently training with a batch size of: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2199\u001b[0m \u001b[38;5;66;03m# Data loader and number of training steps\u001b[39;00m\n\u001b[0;32m-> 2200\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_train_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fsdp_xla_v2_enabled:\n\u001b[1;32m   2202\u001b[0m     train_dataloader \u001b[38;5;241m=\u001b[39m tpu_spmd_dataloader(train_dataloader)\n",
      "File \u001b[0;32m/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/transformers/trainer.py:1000\u001b[0m, in \u001b[0;36mTrainer.get_train_dataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    998\u001b[0m data_collator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_collator\n\u001b[1;32m    999\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_datasets_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(train_dataset, datasets\u001b[38;5;241m.\u001b[39mDataset):\n\u001b[0;32m-> 1000\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_remove_unused_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1002\u001b[0m     data_collator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_collator_with_removed_columns(data_collator, description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/transformers/trainer.py:914\u001b[0m, in \u001b[0;36mTrainer._remove_unused_columns\u001b[0;34m(self, dataset, description)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_signature_columns_if_needed()\n\u001b[1;32m    912\u001b[0m signature_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signature_columns\n\u001b[0;32m--> 914\u001b[0m ignored_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_names\u001b[49m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(signature_columns))\n\u001b[1;32m    915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ignored_columns) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    916\u001b[0m     dset_description \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m description \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdescription\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/mnt/bulk-sirius/anton/coding/SemEval/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:1827\u001b[0m, in \u001b[0;36mDataset.column_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1814\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   1815\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcolumn_names\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m   1816\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Names of the columns in the dataset.\u001b[39;00m\n\u001b[1;32m   1817\u001b[0m \n\u001b[1;32m   1818\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1825\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m   1826\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1827\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[38;5;241m.\u001b[39mcolumn_names\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EmotionDataset' object has no attribute '_data'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 9: Train the Model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 10: Save the Model\n",
    "trainer.save_model(\"distilbert-multilabel-emotion\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 11: Evaluation\n",
    "results = trainer.evaluate(test_dataset)\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
